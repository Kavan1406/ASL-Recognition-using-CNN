{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras import regularizers\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":3,"outputs":[{"output_type":"stream","text":"['asl_alphabet_train', 'asl_alphabet_test']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_dir = '../input/asl_alphabet_train/asl_alphabet_train'\ntest_dir = '../input/asl_alphabet_test/asl_alphabet_test'","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5714d4f2ca8f07d563c25a385d01281fad8ebdb"},"cell_type":"code","source":"def load_unique():\n    size_img = 64,64\n    images_for_plot = []\n    labels_for_plot = []\n    for folder in os.listdir(train_dir):\n        for file in os.listdir(train_dir + '/' + folder):\n            filepath = train_dir + '/' + folder + '/' + file\n            image = cv2.imread(filepath)\n            final_img = cv2.resize(image, size_img)\n            final_img = cv2.cvtColor(final_img, cv2.COLOR_BGR2RGB)\n            images_for_plot.append(final_img)\n            labels_for_plot.append(folder)\n            break\n    return images_for_plot, labels_for_plot\n\nimages_for_plot, labels_for_plot = load_unique()\nprint(\"unique_labels = \", labels_for_plot)","execution_count":5,"outputs":[{"output_type":"stream","text":"unique_labels =  ['N', 'B', 'R', 'P', 'Q', 'X', 'nothing', 'W', 'H', 'Z', 'U', 'T', 'I', 'L', 'C', 'E', 'del', 'J', 'G', 'K', 'F', 'space', 'M', 'S', 'A', 'D', 'O', 'V', 'Y']\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"d40853dbf6c984c4f8522e5b7ff48ec0226bfc37"},"cell_type":"code","source":"labels_dict = {'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'J':9,'K':10,'L':11,'M':12,\n                   'N':13,'O':14,'P':15,'Q':16,'R':17,'S':18,'T':19,'U':20,'V':21,'W':22,'X':23,'Y':24,\n                   'Z':25,'space':26,'del':27,'nothing':28}\n\ndef load_data():\n    images = []\n    labels = []\n    size = 64,64\n    print(\"LOADING DATA FROM : \",end = \"\")\n    for folder in os.listdir(train_dir):\n        print(folder, end = ' | ')\n        for image in os.listdir(train_dir + \"/\" + folder):\n            temp_img = cv2.imread(train_dir + '/' + folder + '/' + image)\n            temp_img = cv2.resize(temp_img, size)\n            images.append(temp_img)\n            if folder == 'A':\n                labels.append(labels_dict['A'])\n            elif folder == 'B':\n                labels.append(labels_dict['B'])\n            elif folder == 'C':\n                labels.append(labels_dict['C'])\n            elif folder == 'D':\n                labels.append(labels_dict['D'])\n            elif folder == 'E':\n                labels.append(labels_dict['E'])\n            elif folder == 'F':\n                labels.append(labels_dict['F'])\n            elif folder == 'G':\n                labels.append(labels_dict['G'])\n            elif folder == 'H':\n                labels.append(labels_dict['H'])\n            elif folder == 'I':\n                labels.append(labels_dict['I'])\n            elif folder == 'J':\n                labels.append(labels_dict['J'])\n            elif folder == 'K':\n                labels.append(labels_dict['K'])\n            elif folder == 'L':\n                labels.append(labels_dict['L'])\n            elif folder == 'M':\n                labels.append(labels_dict['M'])\n            elif folder == 'N':\n                labels.append(labels_dict['N'])\n            elif folder == 'O':\n                labels.append(labels_dict['O'])\n            elif folder == 'P':\n                labels.append(labels_dict['P'])\n            elif folder == 'Q':\n                labels.append(labels_dict['Q'])\n            elif folder == 'R':\n                labels.append(labels_dict['R'])\n            elif folder == 'S':\n                labels.append(labels_dict['S'])\n            elif folder == 'T':\n                labels.append(labels_dict['T'])\n            elif folder == 'U':\n                labels.append(labels_dict['U'])\n            elif folder == 'V':\n                labels.append(labels_dict['V'])\n            elif folder == 'W':\n                labels.append(labels_dict['W'])\n            elif folder == 'X':\n                labels.append(labels_dict['X'])\n            elif folder == 'Y':\n                labels.append(labels_dict['Y'])\n            elif folder == 'Z':\n                labels.append(labels_dict['Z'])\n            elif folder == 'space':\n                labels.append(labels_dict['space'])\n            elif folder == 'del':\n                labels.append(labels_dict['del'])\n            elif folder == 'nothing':\n                labels.append(labels_dict['nothing'])\n    \n    images = np.array(images)\n    images = images.astype('float32')/255.0\n    \n    labels = keras.utils.to_categorical(labels)   #one-hot encoding\n    \n    X_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size = 0.2)\n    \n    print()\n    print('Loaded', len(X_train),'images for training,','Train data shape =',X_train.shape)\n    print('Loaded', len(X_test),'images for testing','Test data shape =',X_test.shape)\n    \n    return X_train, X_test, Y_train, Y_test","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3fe39647e6aa18848b417e46ab57d59037250bc"},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = load_data()\n","execution_count":7,"outputs":[{"output_type":"stream","text":"LOADING DATA FROM : N | B | R | P | Q | X | nothing | W | H | Z | U | T | I | L | C | E | del | J | G | K | F | space | M | S | A | D | O | V | Y | \nLoaded 69600 images for training, Train data shape = (69600, 64, 64, 3)\nLoaded 17400 images for testing Test data shape = (17400, 64, 64, 3)\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"937b0ba698a1809ac587cb4be95d10758761f742"},"cell_type":"code","source":"def build_model():\n    \n    model = Sequential()\n    \n    model.add(Conv2D(64, kernel_size = 3, padding = 'same', activation = 'relu', input_shape = (64,64,3)))\n    model.add(Conv2D(32, kernel_size = 3, padding = 'same', strides = 2, activation = 'relu'))\n    model.add(Dropout(0.5))\n    \n    model.add(Conv2D(32, kernel_size = 3, padding = 'same', activation = 'relu'))\n    model.add(Conv2D(64, kernel_size = 3, padding = 'same', strides = 2, activation = 'relu'))\n    model.add(Dropout(0.5))\n    \n    model.add(Conv2D(128, kernel_size = 3, padding = 'same', activation = 'relu'))\n    model.add(Conv2D(256, kernel_size = 3, padding = 'same', strides = 2 , activation = 'relu'))\n    model.add(MaxPool2D(3))\n    \n    model.add(BatchNormalization())\n    \n    model.add(Flatten())\n    model.add(Dropout(0.5))\n    model.add(Dense(512, activation = 'relu'))\n    model.add(Dense(29, activation = 'softmax'))\n    \n    model.compile(optimizer = 'adam', loss = keras.losses.categorical_crossentropy, metrics = [\"accuracy\"])\n    \n    print(\"MODEL CREATED\")\n    model.summary()\n    \n    return model\n","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4e8f7b003d099733a9e14d58d3c11fde6988cdf"},"cell_type":"code","source":"def fit_model():\n    history = model.fit(X_train, Y_train, batch_size = 64, epochs = 10, validation_split = 0.1)\n    return history","execution_count":14,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":true,"_uuid":"3f8f8ed053d877f626822ab0e3d63121b7f7cdec"},"cell_type":"code","source":"model = build_model()","execution_count":15,"outputs":[{"output_type":"stream","text":"MODEL CREATED\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_7 (Conv2D)            (None, 64, 64, 64)        1792      \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 32, 32, 32)        18464     \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 32, 32, 32)        0         \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 32, 32, 32)        9248      \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 16, 16, 64)        18496     \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 16, 16, 64)        0         \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 16, 16, 128)       73856     \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 8, 8, 256)         295168    \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 2, 2, 256)         0         \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 2, 2, 256)         1024      \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 1024)              0         \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 1024)              0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 512)               524800    \n_________________________________________________________________\ndense_4 (Dense)              (None, 29)                14877     \n=================================================================\nTotal params: 957,725\nTrainable params: 957,213\nNon-trainable params: 512\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"12d6430eb471c1c49f4b20476e08ead216fb2094"},"cell_type":"code","source":"model_history = fit_model()","execution_count":16,"outputs":[{"output_type":"stream","text":"Train on 62640 samples, validate on 6960 samples\nEpoch 1/10\n62640/62640 [==============================] - 21s 335us/step - loss: 1.8920 - acc: 0.4231 - val_loss: 2.5974 - val_acc: 0.4359\nEpoch 2/10\n62640/62640 [==============================] - 20s 321us/step - loss: 0.4839 - acc: 0.8335 - val_loss: 1.8668 - val_acc: 0.5615\nEpoch 3/10\n62640/62640 [==============================] - 21s 330us/step - loss: 0.2547 - acc: 0.9120 - val_loss: 1.0152 - val_acc: 0.7352\nEpoch 4/10\n62640/62640 [==============================] - 20s 325us/step - loss: 0.1746 - acc: 0.9397 - val_loss: 0.3160 - val_acc: 0.8912\nEpoch 5/10\n62640/62640 [==============================] - 20s 323us/step - loss: 0.1495 - acc: 0.9491 - val_loss: 0.9003 - val_acc: 0.7815\nEpoch 6/10\n62640/62640 [==============================] - 21s 328us/step - loss: 0.1219 - acc: 0.9581 - val_loss: 0.2345 - val_acc: 0.9233\nEpoch 7/10\n62640/62640 [==============================] - 20s 323us/step - loss: 0.1130 - acc: 0.9614 - val_loss: 0.0643 - val_acc: 0.9763\nEpoch 8/10\n62640/62640 [==============================] - 20s 323us/step - loss: 0.0953 - acc: 0.9683 - val_loss: 0.3434 - val_acc: 0.8961\nEpoch 9/10\n62640/62640 [==============================] - 21s 329us/step - loss: 0.0861 - acc: 0.9715 - val_loss: 0.2841 - val_acc: 0.9193\nEpoch 10/10\n62640/62640 [==============================] - 20s 325us/step - loss: 0.0829 - acc: 0.9725 - val_loss: 0.1509 - val_acc: 0.9570\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"e1f63b6554a50c641cb08b1d582cbfcfefdfd3d3"},"cell_type":"code","source":"print('Final Accuracy: 97.25%')\nprint('Validation Set Accuracy: 95.70%')","execution_count":23,"outputs":[{"output_type":"stream","text":"Final Accuracy: 97.25%\nValidation Set Accuracy: 95.70%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(X_test,Y_test)\n","execution_count":21,"outputs":[{"output_type":"stream","text":"17400/17400 [==============================] - 2s 137us/step\n","name":"stdout"},{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"[0.15167059929805926, 0.956551724137931]"},"metadata":{}}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}